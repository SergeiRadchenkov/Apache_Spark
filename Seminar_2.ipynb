{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMCiV7H4vkXH"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark >> None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34UGsWuU37r5"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import sum, avg, when, max, month, year\n",
        "from pyspark.sql.functions import countDistinct\n",
        "from pyspark.sql import functions as F\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qnGk_Q__sua"
      },
      "source": [
        "###Задание 1. Напишите программу, которая считывает файл с данными о продажах товаров и вычисляет общую сумму продаж, среднюю сумму продажи и максимальную сумму продажи за каждый месяц. Отсортировать по месяцам. Результаты вывести на экран."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKc1EUI34zXE",
        "outputId": "786d95f4-f603-44be-cb9b-580fa20d3e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+-----------+-----------------+---------+\n",
            "|order_month|total_sales|    average_sales|max_sales|\n",
            "+-----------+-----------+-----------------+---------+\n",
            "|          1|       1300|            650.0|      700|\n",
            "|          2|       2300|766.6666666666666|     1000|\n",
            "|          3|       4500|            900.0|     1100|\n",
            "|          4|       3350|            670.0|     1200|\n",
            "|          5|       3800|            950.0|     1500|\n",
            "|          6|       4650|            775.0|     1350|\n",
            "|          7|       3700|            925.0|     1400|\n",
            "|          8|       2350|783.3333333333334|      900|\n",
            "|          9|       1450|            725.0|      900|\n",
            "|         10|       1350|            675.0|     1200|\n",
            "|         11|       2300|           1150.0|     1350|\n",
            "|         12|       1400|            700.0|      800|\n",
            "+-----------+-----------+-----------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName('Practice').getOrCreate()\n",
        "\n",
        "df_pyspark = spark.read.load('sales_data.csv', format='csv', sep=',', header='true', Infer_schema=True)\n",
        "\n",
        "df_pyspark = df_pyspark.withColumn('order_id', df_pyspark['order_id'].cast('int'))\n",
        "df_pyspark = df_pyspark.withColumn('product_id', df_pyspark['product_id'].cast('int'))\n",
        "df_pyspark = df_pyspark.withColumn('customer_id', df_pyspark['customer_id'].cast('int'))\n",
        "df_pyspark = df_pyspark.withColumn('order_date', df_pyspark['order_date'].cast('date'))\n",
        "df_pyspark = df_pyspark.withColumn('quantity', df_pyspark['quantity'].cast('int'))\n",
        "df_pyspark = df_pyspark.withColumn('price_per_unit', df_pyspark['price_per_unit'].cast('int'))\n",
        "df_pyspark = df_pyspark.withColumn('total_price', df_pyspark['total_price'].cast('int'))\n",
        "\n",
        "df_pyspark = df_pyspark.withColumn('order_month', month(df_pyspark['order_date']))\n",
        "\n",
        "sales_analysis = df_pyspark.groupBy('order_month').agg(\n",
        "    sum('total_price').alias('total_sales'),\n",
        "    avg('total_price').alias('average_sales'),\n",
        "    max('total_price').alias('max_sales'),\n",
        ")\n",
        "sales_analysis.orderBy('order_month').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXo5OK3CC6eB"
      },
      "source": [
        "###Задание 2. Вычислите количество товаров, купленных различными методами оплаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqrGL8uEDIAp",
        "outputId": "575004e6-dae9-423c-e2ac-92920cb7ac28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+------------+\n",
            "|payment_method|num_of_sales|\n",
            "+--------------+------------+\n",
            "|      Наличные|          26|\n",
            "|         Карта|          47|\n",
            "+--------------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sales_analysis = df_pyspark.groupBy('payment_method').agg(sum('quantity').alias('num_of_sales'))\n",
        "sales_analysis.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kSXiDKNDv5j"
      },
      "source": [
        "###Задание 3. Найдите регион с самой большой суммарной стоимостью продаж."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjueSVYPERIo",
        "outputId": "df0804ef-4373-4f86-ce56-73cea78165bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Север\n"
          ]
        }
      ],
      "source": [
        "sales_analysis = df_pyspark.groupBy('region').agg(sum('total_price').alias('total_price_per_region'))\n",
        "total_price_per_region = sales_analysis.select('region').orderBy(sales_analysis.total_price_per_region.desc()).first()\n",
        "print(*total_price_per_region)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssUZ49puFE6Q"
      },
      "source": [
        "###Задание 4. Вычислите общую сумму продаж и среднюю сумму продаж для каждого региона."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0I6Xi34FSui",
        "outputId": "eba1387d-95eb-4fa7-c91e-a5ef64660c6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------------------+--------------------+\n",
            "|region|total_price_per_region|avg_price_per_region|\n",
            "+------+----------------------+--------------------+\n",
            "|    Юг|                  8950|   813.6363636363636|\n",
            "| Запад|                  4800|   533.3333333333334|\n",
            "| Север|                 10200|   927.2727272727273|\n",
            "|Восток|                  8500|   944.4444444444445|\n",
            "+------+----------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sales_analysis = df_pyspark.groupBy('region').agg(sum('total_price').alias('total_price_per_region'), avg('total_price').alias('avg_price_per_region'))\n",
        "sales_analysis.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMA5VHE7Ghvj"
      },
      "source": [
        "###Задание 5. Вычислите общее количество и сумму товаров, проданных за наличные в 2022 году."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KURSFUNYG0Vb",
        "outputId": "2fb3b35b-8c88-47c6-c7c7-07258e468a5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+----------------+\n",
            "|total_quantity_2022|total_price_2022|\n",
            "+-------------------+----------------+\n",
            "|                 12|            4950|\n",
            "+-------------------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark = df_pyspark.withColumn('order_year', year(df_pyspark['order_date']))\n",
        "\n",
        "sales_analysis = df_pyspark.filter((df_pyspark.payment_method == 'Наличные') & (df_pyspark.order_year == 2022)).agg(\n",
        "    sum('quantity').alias('total_quantity_2022'), sum('total_price').alias('total_price_2022'))\n",
        "\n",
        "sales_analysis.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ajdF2e6IVDv"
      },
      "source": [
        "###Задание 6. Найдите уникальное количество покупателей за 2022 году."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3iPrrO8InfG",
        "outputId": "18c97721-c0b9-4b06-fa29-0145ff95ef06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+\n",
            "|unique_users|\n",
            "+------------+\n",
            "|          16|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sales_analysis = df_pyspark.filter(df_pyspark.order_year == 2022)\n",
        "sales_analysis = sales_analysis.select(countDistinct('customer_id').alias('unique_users'))\n",
        "\n",
        "sales_analysis.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMHgLlrzKpfq"
      },
      "source": [
        "###Задание 7. Вам даны данные с информацией о стоимости продуктов в различных валютах. Ваша задача состоит в том, чтобы перевести все цены в доллары, используя текущие курсы валют. Однако у вас есть ограничение: для некоторых продуктов курс валюты неизвестен и их стоимость должна остаться в исходной валюте. (Для конвертации из EUR в USD нужно умножить на 1.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nia0h7vUJ8HX",
        "outputId": "89e5177b-25eb-4b09-8638-99bb657f2c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+--------+---------+\n",
            "|product_id|price|currency|price_usd|\n",
            "+----------+-----+--------+---------+\n",
            "|         1|  100|     USD|    100.0|\n",
            "|         2|  200|     EUR|    240.0|\n",
            "|         3|  300| Unknown|    300.0|\n",
            "|         4|  100|     EUR|    120.0|\n",
            "|         5|  100|     USD|    100.0|\n",
            "|         6|  300| Unknown|    300.0|\n",
            "|         7|  100| Unknown|    100.0|\n",
            "|         8|  200|     USD|    200.0|\n",
            "|         9|  300|     USD|    300.0|\n",
            "+----------+-----+--------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName('currency_conversion').getOrCreate()\n",
        "\n",
        "data = [(1, 100, 'USD'),\n",
        "        (2, 200, 'EUR'),\n",
        "        (3, 300, 'Unknown'),\n",
        "        (4, 100, 'EUR'),\n",
        "        (5, 100, 'USD'),\n",
        "        (6, 300, 'Unknown'),\n",
        "        (7, 100, 'Unknown'),\n",
        "        (8, 200, 'USD'),\n",
        "        (9, 300, 'USD'),]\n",
        "\n",
        "df = spark.createDataFrame(data, ['product_id', 'price', 'currency'])\n",
        "\n",
        "df = df.withColumn('price_usd', when(df.currency == 'USD', df.price).\n",
        "                   when(df.currency == 'EUR', df.price * 1.2).\n",
        "                   otherwise(df.price))\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsNX6EAfOV3Y"
      },
      "source": [
        "###Задание 8. Допустим, есть два датасета: один содержит информацию о пользователях (user_id, name, age), а другой содержит информацию о покупках пользователей (user_id, product_id, date). Необходимо найти средний возраст пользователей, совершивших покупки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osXcAjiDPB93",
        "outputId": "bf3ed2fa-7922-4441-9b6c-487e5ddfe739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----------+\n",
            "|user_id|average_age|\n",
            "+-------+-----------+\n",
            "|      1|       25.0|\n",
            "|      2|       30.0|\n",
            "|      3|       28.0|\n",
            "|      6|       17.0|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName('user_purchase_join').getOrCreate()\n",
        "\n",
        "users_df = spark.createDataFrame([\n",
        "        (1, 'Alice', 25),\n",
        "        (2, 'Bob', 30),\n",
        "        (3, 'Charlie', 28),\n",
        "        (4, 'John', 56),\n",
        "        (5, 'Alex', 41),\n",
        "        (6, 'Julia', 17)], ['user_id', 'name', 'age'])\n",
        "\n",
        "purchases_df = spark.createDataFrame([\n",
        "        (1, 101, '2022-01-01'),\n",
        "        (2, 102, '2022-01-02'),\n",
        "        (3, 103, '2022-01-03'),\n",
        "        (3, 104, '2022-01-04'),\n",
        "        (6, 105, '2022-01-05')], ['user_id', 'product_id', 'date'])\n",
        "\n",
        "result_df = users_df.join(purchases_df, 'user_id').groupBy('user_id').agg(avg('age').alias('average_age'))\n",
        "\n",
        "result_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zfO7yIvB4KC"
      },
      "source": [
        "###Задание 9. У вас есть два набора данных. Первый набор содержит информацию о продуктах: id продукта, название, категория и цена. Второй набор содержит информацию о заказах: id заказа, id продукта, количество. Ваша задача - использовать PySpark для выполнения следующих шагов:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2S4RlQHCo0U"
      },
      "source": [
        "1. Присоединить набор данных о продуктах к набору данных о заказах с помощью id продукта.\n",
        "2. Рассчитать общую стоимость заказа, учитывая количество продуктов и их цену.\n",
        "3. Отфильтровать заказы, у которых общая стоимость больше 1000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aahoptaDDRMM",
        "outputId": "04dd92f0-9aad-465d-cc12-fbc4b75897c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------+--------+---------+---------+-----+----------+\n",
            "|product_id|order_id|quantity|    title| category|price|total_cost|\n",
            "+----------+--------+--------+---------+---------+-----+----------+\n",
            "|         2|       3|     321| product2|category2| 15.0|    4815.0|\n",
            "|         3|       2|     206| product3|category1| 12.5|    2575.0|\n",
            "|         5|       4|     123| product5|category2| 18.0|    2214.0|\n",
            "|         9|      10|      48| product9|category3| 22.0|    1056.0|\n",
            "|        10|       9|     111|product10|category1| 11.5|    1276.5|\n",
            "+----------+--------+--------+---------+---------+-----+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName('aggregate-join-filter').getOrCreate()\n",
        "\n",
        "data_products = [(1, 'product1', 'category1', 10.0),\n",
        "                 (2, 'product2', 'category2', 15.0),\n",
        "                 (3, 'product3', 'category1', 12.5),\n",
        "                 (4, 'product4', 'category3', 20.0),\n",
        "                 (5, 'product5', 'category2', 18.0),\n",
        "                 (6, 'product6', 'category3', 25.0),\n",
        "                 (7, 'product7', 'category1', 9.0),\n",
        "                 (8, 'product8', 'category2', 16.0),\n",
        "                 (9, 'product9', 'category3', 22.0),\n",
        "                 (10, 'product10', 'category1', 11.5)]\n",
        "\n",
        "products_df = spark.createDataFrame(data_products, ['product_id', 'title', 'category', 'price'])\n",
        "\n",
        "data_orders = [(1, 1, 55),\n",
        "               (2, 3, 206),\n",
        "               (3, 2, 321),\n",
        "               (4, 5, 123),\n",
        "               (5, 4, 47),\n",
        "               (6, 7, 27),\n",
        "               (7, 6, 38),\n",
        "               (8, 8, 21),\n",
        "               (9, 10, 111),\n",
        "               (10, 9, 48)]\n",
        "\n",
        "orders_df = spark.createDataFrame(data_orders, ['order_id', 'product_id', 'quantity'])\n",
        "\n",
        "joined_df = orders_df.join(products_df, 'product_id')\n",
        "\n",
        "total_cost_df = joined_df.withColumn('total_cost', F.col('quantity') * F.col('price'))\n",
        "\n",
        "filtered_orders_df = total_cost_df.filter(total_cost_df.total_cost > 1000)\n",
        "\n",
        "filtered_orders_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoXuqje6KYO_"
      },
      "source": [
        "###Задание 10. Найти сумму чисел в колонке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZMfNt77K3l9",
        "outputId": "d68452b8-f641-46ac-c7dc-6ce5cd914a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|sum(number)|\n",
            "+-----------+\n",
            "|         10|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName('sum_example').getOrCreate()\n",
        "\n",
        "data = [(1,), (2,), (3,), (4,)]\n",
        "df = spark.createDataFrame(data, ['number'])\n",
        "\n",
        "sum_result = df.select(sum('number')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtHwEBMrLhMj"
      },
      "source": [
        "###Задание 11. Посчитать количество уникальных значений в колонке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTr9e-MqLq9c",
        "outputId": "35b03a38-c55a-4f34-a00f-52486403207e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|count(DISTINCT name)|\n",
            "+--------------------+\n",
            "|                   3|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName('count_distinct_example').getOrCreate()\n",
        "\n",
        "data = [('Alice',), ('Bob',), ('Alice',), ('Eve',)]\n",
        "df = spark.createDataFrame(data, ['name'])\n",
        "\n",
        "count_result = df.select(countDistinct('name')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBBHd4sGM2tZ"
      },
      "source": [
        "###Задание 12. Выполнить фильтрацию данных по определённому условию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cKDJ57JINDf9",
        "outputId": "1c9ff196-6e74-44d2-caaa-0d9177413f94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|Alice| 25|\n",
            "|  Eve| 20|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName('filter_example').getOrCreate()\n",
        "\n",
        "data = [('Alice', 25), ('Bob', 30), ('Eve', 20), ('Charlie', 35)]\n",
        "df = spark.createDataFrame(data, ['name', 'age'])\n",
        "\n",
        "filtered_data = df.filter(countDistinct('name')).show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}